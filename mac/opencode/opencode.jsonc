{
  "$schema": "https://opencode.ai/config.json",
  "theme": "mysystem",
  "autoupdate": false,
  //"autocompact": false,
  "provider": {
    "lmstudio": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "LM Studio",
      "options": {
        "baseURL": "https://lm.freno.me/v1",
        "apiKey": "{file:~/.config/opencode/my.key}",
      },
      "models": {
        "unsloth/qwen3-coder-30b-a3b-instruct": {"limit":{
        "context": 80000,
        "output": 100000
      }},
        "unsloth/gpt-oss-20b": {"limit":{
        "context": 100000,
        "output": 100000
      }}
      }
    },
    "infill": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Llama-server (infill)",
      "options": {
        "baseURL": "https://infill.freno.me/v1",
        "apiKey": "{file:~/.config/opencode/my.key}",
      },
      "models": {
        "unsloth/qwen3-coder-175k": {"limit":{
        "context": 175000,
        "output": 100000
      }},
        "unsloth/qwen3-coder-150k": {"limit":{
        "context": 150000,
        "output": 100000
      }},
        "unsloth/qwen3-coder-125k": {"limit":{
        "context": 125000,
        "output": 100000
      }},
        "unsloth/qwen3-coder-100k": {"limit":{
        "context": 100000,
        "output": 100000
      }},
        "unsloth/qwen3-coder-70k": {"limit":{
        "context": 70000,
        "output": 100000
      }},
      "unsloth/gpt-oss-20b": {"limit":{
        "context": 131000,
        "output": 100000
      }}
      }
    }
  },
  "lsp": {
    "lua": {
      "command": [
        "lua-language-server"
      ],
      "extensions": [
        ".lua"
      ]
    }
  },
  "formatter": {
    "stylua": {
      "command": [
        "stylua",
        "--check",
        "$FILE"
      ],
      "extensions": [
        ".lua"
      ]
    }
  }
}
